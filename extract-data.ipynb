{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import matplotlib.image as img\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import functools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions from EDA\n",
    "def ejson(p, fn): # extract json\n",
    "    with open((p/fn).as_posix()) as f: return json.load(f) \n",
    "## Simple Json Reading Functions\n",
    "def info_data(p): return ejson(p, 'info.json')\n",
    "def dot_data(p): return ejson(p, 'dotInfo.json')\n",
    "def frame_data(p): return ejson(p, 'frames.json')    \n",
    "def screen_data(p): return ejson(p, 'screen.json')\n",
    "\n",
    "def get_eye_info(i): return ejson(i, 'appleLeftEye.json'), ejson(i, 'appleRightEye.json')\n",
    "def get_face_info(i): return ejson(i, 'appleFace.json')\n",
    "def get_facegrid(i): return ejson(i, 'faceGrid.json')\n",
    "\n",
    "def get_frame(p, img_fn): return img.imread(p/'..'/'..'/'gazecapture-224x224'/p.name/'frames'/img_fn)\n",
    "## Larger Helper Functions\n",
    "def coordinate_data(p): \n",
    "    data = dot_data(p)\n",
    "    return data['XCam'], data['YCam'] # we want relative to camera coords\n",
    "def orientation_data(p):\n",
    "    sdata = screen_data(p)\n",
    "    return sdata['Orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset_path = Path('/media/brennan/Data/ml/gazecapture/')\n",
    "dset_path = Path('../gazecapture/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract File Names For Keras Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1326, 148)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_data(cases, accepted_o=[1, 2, 3, 4]):\n",
    "    fnames = []\n",
    "    XCam, YCam = [], []\n",
    "    FaceH, FaceW, FaceX, FaceY = [], [], [], []\n",
    "    IsValid = []\n",
    "    \n",
    "    i = 0\n",
    "    for case in cases:\n",
    "        FRAME_N = frame_data(case)\n",
    "        O = orientation_data(case)\n",
    "        XCAM, YCAM = coordinate_data(case)\n",
    "#         LE, RE = get_eye_info(case)\n",
    "        FACE = get_face_info(case)\n",
    "\n",
    "        for frame_n, o, xcam, ycam, \\\n",
    "            fh, fw, fx, fy, valid in zip(FRAME_N, O, XCAM, YCAM, \n",
    "                                 FACE['H'], FACE['W'], FACE['X'], FACE['Y'], FACE['IsValid']):\n",
    "            if o in accepted_o:\n",
    "                fnames.append('{}/frames/{}'.format(case.name, frame_n))\n",
    "                XCam.append(xcam)\n",
    "                YCam.append(ycam)\n",
    "                IsValid.append(valid)\n",
    "                FaceH.append(fh)\n",
    "                FaceW.append(fw)\n",
    "                FaceX.append(fx)\n",
    "                FaceY.append(fy)\n",
    "\n",
    "    # package to dataframe\n",
    "    df = pd.DataFrame(data={'file_names': fnames, \n",
    "                            'XCam': XCam,\n",
    "                            'YCam': YCam,\n",
    "                            'IsValid': IsValid,\n",
    "                            'FaceH': FaceH, \n",
    "                            'FaceW': FaceW,\n",
    "                            'FaceX': FaceX,\n",
    "                            'FaceY': FaceY})        \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all case names first to split => faces it hasnt seen before\n",
    "train_cases, test_cases = train_test_split(list(dset_path.iterdir()), test_size=test_size)\n",
    "len(train_cases), len(test_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract all Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from data\n",
    "# ALL PHOTOS split into train / test sets\n",
    "train_df = extract_data(train_cases)\n",
    "test_df = extract_data(test_cases)\n",
    "\n",
    "train_df.to_csv('train-df.csv')\n",
    "test_df.to_csv('test-df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract ONLY Portrait Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = extract_data(train_cases, accepted_o=[1])\n",
    "test_df = extract_data(test_cases, accepted_o=[1])\n",
    "# train_df.to_csv('portrait-train-df.csv')\n",
    "# test_df.to_csv('portrait-test-df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09879818605173366, 0.9012018139482664)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df) / (len(test_df) + len(train_df)), len(train_df) / (len(test_df) + len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80958, 738470)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df), len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract & Split LandScape Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = extract_data(train_cases, accepted_o=[3, 4])\n",
    "test_df = extract_data(test_cases, accepted_o=[3, 4])\n",
    "train_df.to_csv('landscape-train-df.csv')\n",
    "test_df.to_csv('landscape-test-df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strain, sval = train_test_split(train_df, test_size=0.1)\n",
    "strain.to_csv('landscape-traindf.csv'), sval.to_csv('landscape-valdf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 & 2 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_sample = train_df.sample(frac=0.5)\n",
    "strain, sval = train_test_split(train_df_sample, test_size=0.1)\n",
    "strain.to_csv('traindf_sample.csv'), sval.to_csv('valdf_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Prev Stage Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df = pd.read_csv('portrait-traindf.csv')\n",
    "file_names = old_df['file_names'].values\n",
    "cases_to_update = []\n",
    "\n",
    "for fn in file_names:\n",
    "    case = fn[:fn.index('/')]\n",
    "    if not (dset_path / case in cases_to_update):\n",
    "        cases_to_update.append(dset_path / case)\n",
    "\n",
    "new_train_df = extract_data(cases_to_update, accepted_o=[1])\n",
    "strain, sval = train_test_split(new_train_df, test_size=0.1)\n",
    "strain.to_csv('portrait-traindf.csv'), sval.to_csv('portrait-valdf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to hdf5\n",
    "Not Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extracting and storing X values\n",
    "# def extract_photo(f, case): return get_frame(case, f)\n",
    "\n",
    "# def extract(case):\n",
    "#     F = frame_data(case) # list of file names correlated to camera images \n",
    "#     with Pool(6) as p:  # multi core usale\n",
    "#         x = p.map(functools.partial(extract_photo, case=case), F)\n",
    "#     return x\n",
    "\n",
    "# def extract_to_hdf5(cname, bs, extract_fcn): # bs dsets per hp5y file\n",
    "#     f = h5py.File('{}-0.hdf5'.format(cname), 'w') \n",
    "#     for i, case in enumerate(list(dset_path.iterdir())):\n",
    "#         cn = case.name\n",
    "#         edata = extract_fcn(case)\n",
    "        \n",
    "#         dset = f.create_dataset('dset'+cn, (len(edata), 224, 224, 3))\n",
    "#         dset[...] = edata\n",
    "\n",
    "#         if i % bs == 0 and i!= 0:\n",
    "#             f.close()\n",
    "#             f = h5py.File('{}-{}.hdf5'.format(cname, i//bs), 'w')\n",
    "# extract_to_hdf5('X', 500, extract)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
