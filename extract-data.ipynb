{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import matplotlib.image as img\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import functools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions from EDA\n",
    "def ejson(p, fn): # extract json\n",
    "    with open((p/fn).as_posix()) as f: return json.load(f) \n",
    "## Simple Json Reading Functions\n",
    "def info_data(p): return ejson(p, 'info.json')\n",
    "def dot_data(p): return ejson(p, 'dotInfo.json')\n",
    "def frame_data(p): return ejson(p, 'frames.json')    \n",
    "def screen_data(p): return ejson(p, 'screen.json')\n",
    "\n",
    "def get_eye_info(i): return ejson(i, 'appleLeftEye.json'), ejson(i, 'appleRightEye.json')\n",
    "def get_face_info(i): return ejson(i, 'appleFace.json')\n",
    "def get_facegrid(i): return ejson(i, 'faceGrid.json')\n",
    "\n",
    "def get_frame(p, img_fn): return img.imread(p/'..'/'..'/'gazecapture-224x224'/p.name/'frames'/img_fn)\n",
    "## Larger Helper Functions\n",
    "def coordinate_data(p): \n",
    "    data = dot_data(p)\n",
    "    return data['XCam'], data['YCam'] # we want relative to camera coords\n",
    "def orientation_data(p):\n",
    "    sdata = screen_data(p)\n",
    "    return sdata['Orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset_path = Path('/media/brennan/Data/ml/gazecapture/')\n",
    "dset_path = Path('../gazecapture/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract File Names For Keras Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_cases = ['02984',\n",
    "                 '02032',\n",
    "                 '01030',\n",
    "                 '01152',\n",
    "                 '00325',\n",
    "                 '02622',\n",
    "                 '00827',\n",
    "                 '02119',\n",
    "                 '00927',\n",
    "                 '03277',\n",
    "                 '02190',\n",
    "                 '01282',\n",
    "                 '00808',\n",
    "                 '01474',\n",
    "                 '01805',\n",
    "                 '00207',\n",
    "                 '00666',\n",
    "                 '01066',\n",
    "                 '01243',\n",
    "                 '01269',\n",
    "                 '01661',\n",
    "                 '02048',\n",
    "                 '01266',\n",
    "                 '00619',\n",
    "                 '00779',\n",
    "                 '01090',\n",
    "                 '03059',\n",
    "                 '01432',\n",
    "                 '01225',\n",
    "                 '03060',\n",
    "                 '02781',\n",
    "                 '00138',\n",
    "                 '02526',\n",
    "                 '01353',\n",
    "                 '02967',\n",
    "                 '02093',\n",
    "                 '02165']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1326, 148)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_data(cases, accepted_o=[1, 2, 3, 4]):\n",
    "    fnames = []\n",
    "    XCam, YCam = [], []\n",
    "    FaceH, FaceW, FaceX, FaceY = [], [], [], []\n",
    "    IsValid = []\n",
    "    \n",
    "    i = 0\n",
    "    for case in cases:\n",
    "        if not (case in invalid_cases):\n",
    "            FRAME_N = frame_data(case)\n",
    "            O = orientation_data(case)\n",
    "            XCAM, YCAM = coordinate_data(case)\n",
    "    #         LE, RE = get_eye_info(case)\n",
    "            FACE = get_face_info(case)\n",
    "\n",
    "            for frame_n, o, xcam, ycam, \\\n",
    "                fh, fw, fx, fy, valid in zip(FRAME_N, O, XCAM, YCAM, \n",
    "                                     FACE['H'], FACE['W'], FACE['X'], FACE['Y'], FACE['IsValid']):\n",
    "                if o in accepted_o and valid == 1:\n",
    "                    fnames.append('{}/frames/{}'.format(case.name, frame_n))\n",
    "                    XCam.append(xcam)\n",
    "                    YCam.append(ycam)\n",
    "                    IsValid.append(valid)\n",
    "                    FaceH.append(fh)\n",
    "                    FaceW.append(fw)\n",
    "                    FaceX.append(fx)\n",
    "                    FaceY.append(fy)\n",
    "\n",
    "    # package to dataframe\n",
    "    df = pd.DataFrame(data={'file_names': fnames, \n",
    "                            'XCam': XCam,\n",
    "                            'YCam': YCam,\n",
    "                            'IsValid': IsValid,\n",
    "                            'FaceH': FaceH, \n",
    "                            'FaceW': FaceW,\n",
    "                            'FaceX': FaceX,\n",
    "                            'FaceY': FaceY})        \n",
    "    \n",
    "    return df\n",
    "\n",
    "# Extract all case names first to split => faces it hasnt seen before\n",
    "train_cases, test_cases = train_test_split(list(dset_path.iterdir()), test_size=test_size)\n",
    "len(train_cases), len(test_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract all Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from data\n",
    "# ALL PHOTOS split into train / test sets\n",
    "train_df = extract_data(train_cases)\n",
    "test_df = extract_data(test_cases)\n",
    "\n",
    "train_df.to_csv('train-df.csv')\n",
    "test_df.to_csv('test-df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract ONLY Portrait Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = extract_data(train_cases, accepted_o=[1])\n",
    "test_df = extract_data(test_cases, accepted_o=[1])\n",
    "train_df.to_csv('portrait-data/traindf.csv')\n",
    "test_df.to_csv('portrait-data/testdf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82893, 693269)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df), len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10679858070866649, 0.8932014192913336)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df) / (len(test_df) + len(train_df)), len(train_df) / (len(test_df) + len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract & Split LandScape Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = extract_data(train_cases, accepted_o=[3])\n",
    "test_df = extract_data(test_cases, accepted_o=[3])\n",
    "train_df.to_csv('landscape-r-data/traindf.csv')\n",
    "test_df.to_csv('landscape-r-data/testdf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = extract_data(train_cases, accepted_o=[4])\n",
    "test_df = extract_data(test_cases, accepted_o=[4])\n",
    "train_df.to_csv('landscape-l-data/traindf.csv')\n",
    "test_df.to_csv('landscape-l-data/testdf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 & 2 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_sample = train_df.sample(frac=0.5)\n",
    "# strain, sval = train_test_split(train_df_sample, test_size=0.1)\n",
    "# strain.to_csv('traindf_sample.csv'), sval.to_csv('valdf_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Prev Stage Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old_df = pd.read_csv('portrait-traindf.csv')\n",
    "# file_names = old_df['file_names'].values\n",
    "# cases_to_update = []\n",
    "\n",
    "# for fn in file_names:\n",
    "#     case = fn[:fn.index('/')]\n",
    "#     if not (dset_path / case in cases_to_update):\n",
    "#         cases_to_update.append(dset_path / case)\n",
    "\n",
    "# new_train_df = extract_data(cases_to_update, accepted_o=[1])\n",
    "# strain, sval = train_test_split(new_train_df, test_size=0.1)\n",
    "# strain.to_csv('portrait-traindf.csv'), sval.to_csv('portrait-valdf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to hdf5\n",
    "Not Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extracting and storing X values\n",
    "# def extract_photo(f, case): return get_frame(case, f)\n",
    "\n",
    "# def extract(case):\n",
    "#     F = frame_data(case) # list of file names correlated to camera images \n",
    "#     with Pool(6) as p:  # multi core usale\n",
    "#         x = p.map(functools.partial(extract_photo, case=case), F)\n",
    "#     return x\n",
    "\n",
    "# def extract_to_hdf5(cname, bs, extract_fcn): # bs dsets per hp5y file\n",
    "#     f = h5py.File('{}-0.hdf5'.format(cname), 'w') \n",
    "#     for i, case in enumerate(list(dset_path.iterdir())):\n",
    "#         cn = case.name\n",
    "#         edata = extract_fcn(case)\n",
    "        \n",
    "#         dset = f.create_dataset('dset'+cn, (len(edata), 224, 224, 3))\n",
    "#         dset[...] = edata\n",
    "\n",
    "#         if i % bs == 0 and i!= 0:\n",
    "#             f.close()\n",
    "#             f = h5py.File('{}-{}.hdf5'.format(cname, i//bs), 'w')\n",
    "# extract_to_hdf5('X', 500, extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Split Which Was Used In The Paper\n",
    "http://gazecapture.csail.mit.edu/cvpr2016_gazecapture.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.fnames = []\n",
    "        self.XCam = []\n",
    "        self.YCam = []\n",
    "        self.IsValid = []\n",
    "        self.FaceH, self.FaceW, self.FaceX, self.FaceY = [], [], [], []\n",
    "    \n",
    "    def append(self, fname, xcam, ycam, valid, fh, fw, fx, fy):\n",
    "        self.fnames.append(fname)\n",
    "        self.XCam.append(xcam)\n",
    "        self.YCam.append(ycam)\n",
    "        self.IsValid.append(valid)\n",
    "        self.FaceH.append(fh)\n",
    "        self.FaceW.append(fw)\n",
    "        self.FaceX.append(fx)\n",
    "        self.FaceY.append(fy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_split(cases, accepted_o=[1, 2, 3, 4]):\n",
    "    train, val, test = Dataset(), Dataset(), Dataset()\n",
    "    \n",
    "    i = 0\n",
    "    for case in cases:\n",
    "        if not (case in invalid_cases):\n",
    "            FRAME_N = frame_data(case)\n",
    "            O = orientation_data(case)\n",
    "            XCAM, YCAM = coordinate_data(case)\n",
    "            dset = info_data(case)['Dataset']\n",
    "            FACE = get_face_info(case)\n",
    "            \n",
    "            if dset == 'train': dataset = train\n",
    "            elif dset == 'val': dataset = val\n",
    "            elif dset == 'test': dataset = test\n",
    "\n",
    "            for frame_n, o, xcam, ycam, \\\n",
    "                fh, fw, fx, fy, valid in zip(FRAME_N, O, XCAM, YCAM, \n",
    "                                     FACE['H'], FACE['W'], FACE['X'], FACE['Y'], FACE['IsValid']):\n",
    "                if o in accepted_o and valid == 1:\n",
    "                    dataset.append('{}/frames/{}'.format(case.name, frame_n), \n",
    "                                   xcam, \n",
    "                                   ycam,\n",
    "                                   valid,\n",
    "                                   fh, fw, fx, fy)\n",
    "    \n",
    "    dset_df = []\n",
    "    for dataset in [train, test, val]:\n",
    "        # package to dataframe\n",
    "        df = pd.DataFrame(data={'file_names': dataset.fnames, \n",
    "                                'XCam': dataset.XCam,\n",
    "                                'YCam': dataset.YCam,\n",
    "                                'IsValid': dataset.IsValid,\n",
    "                                'FaceH': dataset.FaceH, \n",
    "                                'FaceW': dataset.FaceW,\n",
    "                                'FaceX': dataset.FaceX,\n",
    "                                'FaceY': dataset.FaceY})        \n",
    "        dset_df.append(df)\n",
    "\n",
    "    return dset_df[0], dset_df[1], dset_df[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../gazecapture/02942/frames.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-80483a196f8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraindf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaldf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccepted_o\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-2dcaea81e773>\u001b[0m in \u001b[0;36mextract_split\u001b[0;34m(cases, accepted_o)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minvalid_cases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mFRAME_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morientation_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mXCAM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYCAM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5816c5ff7477>\u001b[0m in \u001b[0;36mframe_data\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minfo_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mejson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'info.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mejson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dotInfo.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mframe_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mejson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'frames.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscreen_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mejson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'screen.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5816c5ff7477>\u001b[0m in \u001b[0;36mejson\u001b[0;34m(p, fn)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Helper Functions from EDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mejson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# extract json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m## Simple Json Reading Functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minfo_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mejson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'info.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../gazecapture/02942/frames.json'"
     ]
    }
   ],
   "source": [
    "traindf, valdf, testdf = extract_split(list(dset_path.iterdir()), accepted_o=[1])\n",
    "traindf.to_csv('papersplit/portrait/traindf.csv')\n",
    "valdf.to_csv('papersplit/portrait/valdf.csv')\n",
    "testdf.to_csv('papersplit/portrait/testdf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
